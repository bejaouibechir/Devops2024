# Projet 1 â€“ Ã‰noncÃ© officiel

---

## Partie I mise en marche manuelle

## Objectif du projet

DÃ©ployer, valider et tester **une application Kubernetes complÃ¨te** incluant :

- **MySQL persistante**

- **Backend Flask scalable**

- **Autoscaling HPA**

- **Monitoring MySQL**

- **Tests fonctionnels et techniques**

---

## PrÃ©-requis obligatoires

Avant de commencer, lâ€™apprenant doit disposer de :

- Un **cluster Kubernetes fonctionnel**

- Un environnement **Minikube OU cluster standard**

- Un environnement de **build dâ€™images Docker**

- Le code source du **Projet 1**

---

## Ã‰tape 1 â€“ PrÃ©parer le cluster Kubernetes

1. DÃ©marrer le **cluster Kubernetes**.

2. VÃ©rifier la disponibilitÃ© du **stockage persistant**.

3. VÃ©rifier la disponibilitÃ© des **mÃ©triques Kubernetes**.

RÃ©sultat attendu :

- Le cluster est **Ready** et stable.

---

## Ã‰tape 2 â€“ DÃ©ployer la base MySQL

1. CrÃ©er un **namespace dÃ©diÃ©**.

2. DÃ©finir les **secrets MySQL**.

3. DÃ©finir les **scripts dâ€™initialisation**.

4. DÃ©ployer MySQL sous forme de **StatefulSet**.

5. Exposer MySQL via des **services internes**.

RÃ©sultat attendu :

- MySQL est **Running**

- Les donnÃ©es sont **persistÃ©es**

- La base est **accessible depuis le cluster**

---

## Ã‰tape 3 â€“ Construire et rendre disponible lâ€™image du backend Flask

**(Ã‰tape critique)**

### Cas 1 â€“ Environnement Minikube

1. Construire lâ€™image Docker **dans lâ€™environnement Docker de Minikube**.

2. VÃ©rifier que lâ€™image est **directement disponible localement**.

3. Sâ€™assurer que Kubernetes peut consommer lâ€™image **sans registry externe**.

### Cas 2 â€“ Cluster Kubernetes standard

1. Construire lâ€™image Docker.

2. **Taguer lâ€™image** pour un registry valide.

3. **Pousser lâ€™image** vers un **Docker registry**.

4. Configurer Kubernetes pour **tirer lâ€™image**.

RÃ©sultat attendu :

- Lâ€™image du backend est **accessible par Kubernetes**.

---

## Ã‰tape 4 â€“ DÃ©ployer le backend Flask

1. DÃ©finir les **secrets applicatifs**.

2. DÃ©ployer le backend via un **Deployment**.

3. Configurer la **connexion MySQL interne**.

4. Exposer lâ€™API via un **Service Kubernetes**.

5. Activer lâ€™**autoscaling HPA**.

RÃ©sultat attendu :

- Le backend est **Running**

- Plusieurs rÃ©plicas sont actifs

- La communication MySQL est fonctionnelle

---

## Ã‰tape 5 â€“ Tests techniques Kubernetes

**(Validation dâ€™infrastructure)**

1. VÃ©rifier lâ€™Ã©tat des **pods MySQL**.

2. VÃ©rifier lâ€™Ã©tat des **pods backend**.

3. VÃ©rifier que les **probes** fonctionnent.

4. VÃ©rifier la rÃ©solution **DNS interne** entre backend et MySQL.

5. VÃ©rifier lâ€™absence dâ€™erreurs de type **CrashLoopBackOff** ou **ImagePullBackOff**.

RÃ©sultat attendu :

- Tous les pods sont **Ready**

- Aucun Ã©vÃ©nement critique Kubernetes

---

## Ã‰tape 6 â€“ Tests fonctionnels de lâ€™API

**(Validation applicative)**

1. AccÃ©der Ã  lâ€™API exposÃ©e par Kubernetes.

2. Tester lâ€™endpoint de **santÃ© applicative**.

3. Tester un **appel simple de lecture**.

4. Tester un **appel de crÃ©ation**.

5. Tester un **appel de mise Ã  jour**.

6. Tester un **appel de suppression**.

RÃ©sultat attendu :

- Toutes les opÃ©rations API fonctionnent

- Les donnÃ©es sont bien **persistÃ©es en base**

Astuce :

- Les tests doivent prouver que **lâ€™Ã©tat survit** Ã  un redÃ©marrage de pod.

---

## Ã‰tape 7 â€“ Tests de rÃ©silience

**(Comportement en cas dâ€™incident)**

1. Forcer lâ€™arrÃªt dâ€™un **pod backend**.

2. Observer le **redÃ©marrage automatique**.

3. VÃ©rifier que lâ€™API reste accessible.

4. Forcer lâ€™arrÃªt du **pod MySQL**.

5. VÃ©rifier la reprise avec **donnÃ©es intactes**.

RÃ©sultat attendu :

- Kubernetes assure la **continuitÃ© de service**

- Aucune perte de donnÃ©es

---

## Ã‰tape 8 â€“ Installer la stack de monitoring

1. Installer une stack **Prometheus + Grafana**.

2. VÃ©rifier la collecte des **mÃ©triques cluster**.

3. VÃ©rifier lâ€™accÃ¨s Ã  **Grafana**.

RÃ©sultat attendu :

- Prometheus et Grafana sont **opÃ©rationnels**

---

## Ã‰tape 9 â€“ Tests de monitoring MySQL

1. DÃ©ployer lâ€™**exporter MySQL**.

2. VÃ©rifier que Prometheus **scrape les mÃ©triques**.

3. VÃ©rifier les **dashboards MySQL**.

4. VÃ©rifier lâ€™activation des **rÃ¨gles dâ€™alerte**.

RÃ©sultat attendu :

- Les mÃ©triques MySQL sont visibles

- Les alertes sont prÃªtes Ã  Ãªtre dÃ©clenchÃ©es

---

## Ã‰tape 10 â€“ Tests de charge et autoscaling

1. GÃ©nÃ©rer une **charge applicative contrÃ´lÃ©e**.

2. Observer lâ€™Ã©volution de la **consommation CPU/MÃ©moire**.

3. Observer le comportement du **HPA**.

4. VÃ©rifier la crÃ©ation de **nouveaux pods backend**.

5. VÃ©rifier la stabilisation aprÃ¨s la charge.

RÃ©sultat attendu :

- Le backend **scale automatiquement**

- Le service reste fonctionnel sous charge

---

## Ã‰tape 11 â€“ Nettoyage de lâ€™environnement

1. Supprimer les ressources applicatives.

2. Supprimer les namespaces crÃ©Ã©s.

3. VÃ©rifier que le cluster est **propre**.

RÃ©sultat attendu :

- Aucun rÃ©sidu du Projet 1

---

## Partie II Tester les scripts

TrÃ¨s bonne question â€” et elle est **structurante** pour comprendre le **sens du projet**, pas juste son exÃ©cution.

Je rÃ©ponds **en style Microsoft**, clair, factuel, **sans blabla**, en expliquant **le rÃ´le prÃ©cis de chaque script .sh** et **pourquoi ils existent** dans Projet 1.

---

# Projet 1 â€“ RÃ´le des scripts .sh

Les scripts shell **nâ€™implÃ©mentent pas la solution**.  
Ils servent Ã  **orchestrer**, **tester** et **dÃ©montrer** le projet.

ğŸ‘‰ Le projet doit Ãªtre **exÃ©cutable sans eux**.  
ğŸ‘‰ Les scripts sont des **accÃ©lÃ©rateurs dâ€™atelier**, pas une dÃ©pendance.

---

## 1. scripts/deploy-all.sh

### RÃ´le

Automatiser la **mise en route complÃ¨te du Projet 1** sur un poste local.

### Ã€ quoi il sert

- DÃ©marrer lâ€™environnement **Minikube**

- Activer les **addons requis**

- Construire et rendre disponible lâ€™image backend

- DÃ©ployer **MySQL**, **backend**, **HPA**

- Installer la stack **Prometheus + Grafana**

- Appliquer le **monitoring MySQL**

### Pourquoi il existe

- Gagner du temps en **atelier**

- Ã‰viter les erreurs de saisie

- Permettre une **dÃ©mo rapide formateur**

### Ã€ retenir

- Ce script **nâ€™est pas requis** pour comprendre Kubernetes

- Il **masque volontairement** des commandes que lâ€™apprenant doit savoir refaire

---

## 2. scripts/load-test.sh ou load-test.js

### RÃ´le

GÃ©nÃ©rer une **charge contrÃ´lÃ©e** sur lâ€™API.

### Ã€ quoi il sert

- Simuler des **requÃªtes clients**

- CrÃ©er de la pression CPU et MySQL

- DÃ©clencher le **HPA**

- Observer le **scaling automatique**

### Pourquoi il existe

- Tester le projet **au-delÃ  du â€œÃ§a marcheâ€**

- Rendre visible lâ€™intÃ©rÃªt de :
  
  - HPA
  
  - Monitoring
  
  - Metrics Server

### Ã€ retenir

- Ce script valide le **fil rouge performance**

- Sans lui, le HPA reste **invisible**

---

## 3. scripts/test-api.sh

### RÃ´le

Tester rapidement les **endpoints fonctionnels** de lâ€™API.

### Ã€ quoi il sert

- VÃ©rifier lâ€™endpoint **health**

- Tester les opÃ©rations **CRUD**

- Valider la connexion MySQL

### Pourquoi il existe

- VÃ©rifier que le backend est **fonctionnel**

- DÃ©tecter rapidement une erreur de configuration

### Ã€ retenir

- Ce script est un **smoke test**

- Il ne remplace pas des tests automatisÃ©s complets

---

## 4. scripts/monitoring-check.sh

### RÃ´le

Valider que le **monitoring fonctionne rÃ©ellement**.

### Ã€ quoi il sert

- VÃ©rifier que lâ€™exporter MySQL est **UP**

- VÃ©rifier que Prometheus **scrape les mÃ©triques**

- VÃ©rifier la prÃ©sence des **alert rules**

### Pourquoi il existe

- Ã‰viter le faux sentiment â€œtout est installÃ©â€

- Forcer une **validation factuelle**

### Ã€ retenir

- Monitoring sans vÃ©rification = **monitoring inutile**

---

## 5. scripts/cleanup.sh

### RÃ´le

Nettoyer proprement lâ€™environnement.

### Ã€ quoi il sert

- Supprimer les namespaces crÃ©Ã©s

- LibÃ©rer les volumes

- Remettre le cluster dans un Ã©tat propre

### Pourquoi il existe

- RÃ©initialiser lâ€™atelier

- Ã‰viter les conflits entre sessions

- Permettre des rÃ©pÃ©titions rapides

### Ã€ retenir

- Le nettoyage fait partie du **cycle de vie Kubernetes**

---

## SynthÃ¨se â€“ Pourquoi ces scripts existent

| Script           | RÃ´le principal                |
| ---------------- | ----------------------------- |
| deploy-all.sh    | DÃ©marrage rapide de lâ€™atelier |
| load-test        | DÃ©monstration HPA             |
| test-api         | Validation fonctionnelle      |
| monitoring-check | Validation observabilitÃ©      |
| cleanup          | Fin propre de lâ€™atelier       |

Parfait ğŸ‘  
Tu mets le doigt sur **le chaÃ®non manquant** :  
les scripts existent, mais **lâ€™apprenant doit comprendre comment les activer, les suivre et les auditer**, pas juste les lancer comme une boÃ®te noire.

Je tâ€™ajoute donc **une section dÃ©diÃ©e**, Ã  intÃ©grer **dans lâ€™Ã©noncÃ© du Projet 1**, toujours :

- **Style Microsoft tutorial**

- **Instructions claires**

- **Ã‰tapes numÃ©rotÃ©es**

- **Mots-clÃ©s en gras**

- **Aucune commande**

- **Orientation â€œobserver / comprendre / validerâ€**

---

# Projet 1 â€“ Mise en action et analyse des scripts

---

## Objectif de cette partie

Apprendre Ã  :

- **Lancer manuellement** chaque script

- **Comprendre ce quâ€™il dÃ©clenche**

- **Observer son impact rÃ©el** dans Kubernetes

- **Valider que le rÃ©sultat attendu est atteint**

Les scripts sont utilisÃ©s comme **outil dâ€™observation**, pas comme solution magique.

---

## Ã‰tape 12 â€“ PrÃ©parer lâ€™exÃ©cution des scripts

1. Identifier le dossier **scripts** du projet.

2. Examiner la liste des scripts disponibles.

3. Lire chaque script **avant exÃ©cution**.

4. Identifier :
   
   - Les **ressources Kubernetes** manipulÃ©es
   
   - Les **outils utilisÃ©s**
   
   - Les **actions automatisÃ©es**

RÃ©sultat attendu :

- Lâ€™apprenant sait **ce que chaque script va faire** avant de le lancer.

---

## Ã‰tape 13 â€“ Mettre en marche le script de dÃ©ploiement global

### Script concernÃ©

- **deploy-all.sh**

### Instructions

1. Examiner les sections du script.

2. Identifier :
   
   - La phase **prÃ©paration du cluster**
   
   - La phase **construction dâ€™image**
   
   - La phase **dÃ©ploiement Kubernetes**
   
   - La phase **monitoring**

3. Lancer le script **en mode contrÃ´lÃ©**.

4. Observer lâ€™exÃ©cution **ligne par ligne**.

Points dâ€™observation obligatoires :

- CrÃ©ation des **namespaces**

- DÃ©ploiement des **pods**

- Attente de lâ€™Ã©tat **Ready**

- Installation des composants de monitoring

RÃ©sultat attendu :

- Lâ€™ensemble des composants du Projet 1 est dÃ©ployÃ© automatiquement.

Astuce :

- Toute erreur affichÃ©e doit Ãªtre **analysÃ©e**, pas ignorÃ©e.

---

## Ã‰tape 14 â€“ Examiner lâ€™impact du dÃ©ploiement

1. VÃ©rifier lâ€™Ã©tat des **pods MySQL**.

2. VÃ©rifier lâ€™Ã©tat des **pods backend**.

3. VÃ©rifier la prÃ©sence des **services**.

4. VÃ©rifier la crÃ©ation du **HPA**.

5. VÃ©rifier la crÃ©ation des **ressources de monitoring**.

RÃ©sultat attendu :

- Toutes les ressources attendues sont prÃ©sentes et opÃ©rationnelles.

---

## Ã‰tape 15 â€“ Mettre en marche le script de test API

### Script concernÃ©

- **test-api.sh**

### Instructions

1. Examiner les appels effectuÃ©s par le script.

2. Identifier les **endpoints API** testÃ©s.

3. Lancer le script.

4. Observer les rÃ©ponses retournÃ©es par lâ€™API.

Points de contrÃ´le :

- Endpoint de **santÃ©**

- OpÃ©rations de **lecture**

- OpÃ©rations de **crÃ©ation**

- OpÃ©rations de **suppression**

RÃ©sultat attendu :

- Lâ€™API rÃ©pond correctement Ã  toutes les opÃ©rations.

---

## Ã‰tape 16 â€“ Mettre en marche le script de charge

### Script concernÃ©

- **load-test** (shell ou k6)

### Instructions

1. Examiner le scÃ©nario de charge.

2. Identifier :
   
   - Le **nombre de requÃªtes**
   
   - La **durÃ©e**
   
   - Les **endpoints sollicitÃ©s**

3. Lancer le script de charge.

4. Observer le comportement du cluster **pendant lâ€™exÃ©cution**.

Points dâ€™observation obligatoires :

- Augmentation de la charge CPU

- Ã‰volution du **HPA**

- CrÃ©ation de **nouveaux pods backend**

RÃ©sultat attendu :

- Le backend scale automatiquement sous charge.

---

## Ã‰tape 17 â€“ Examiner le monitoring en temps rÃ©el

### Script concernÃ©

- **monitoring-check.sh**

### Instructions

1. Examiner ce que le script vÃ©rifie.

2. Identifier les mÃ©triques MySQL ciblÃ©es.

3. Lancer le script.

4. Comparer les rÃ©sultats avec lâ€™interface Grafana.

Points de contrÃ´le :

- Exporter MySQL **UP**

- MÃ©triques visibles dans Prometheus

- DonnÃ©es cohÃ©rentes dans Grafana

RÃ©sultat attendu :

- Le monitoring reflÃ¨te fidÃ¨lement lâ€™activitÃ© rÃ©elle.

---

## Ã‰tape 18 â€“ Nettoyer via script

### Script concernÃ©

- **cleanup.sh**

### Instructions

1. Examiner les ressources supprimÃ©es par le script.

2. VÃ©rifier quâ€™aucune ressource critique hors projet nâ€™est impactÃ©e.

3. Lancer le script de nettoyage.

4. VÃ©rifier lâ€™Ã©tat final du cluster.

RÃ©sultat attendu :

- Le cluster est **vide de toute ressource Projet 1**.

---

## Message clÃ© pour lâ€™apprenant

- Un script est **un raccourci**, pas une compÃ©tence.

- Chaque script correspond Ã  une **sÃ©quence Kubernetes** reproductible manuellement.

- Lâ€™objectif final est de **savoir expliquer ce que fait le script sans lâ€™exÃ©cuter**.

## Objectif

Automatiser Projet 1 avec GitLab CI :

- Construire lâ€™image Docker du backend

- Taguer et publier lâ€™image dans le Registry GitLab

- DÃ©ployer les manifests Kubernetes sur une machine EC2 dÃ©jÃ  prÃªte

- ExÃ©cuter les scripts sh cÃ´tÃ© EC2 pour orchestrer le dÃ©ploiement et les tests

- Tout secret, IP, clÃ©, mot de passe doit passer via des variables GitLab CI

---

# DÃ©marche GitLab CI pour Projet 1

## 1) PrÃ©parer le dÃ©pÃ´t GitLab

1. CrÃ©er le projet GitLab et pousser :
   
   - Code backend
   
   - Manifests Kubernetes
   
   - Dossier scripts

2. Activer le Registry GitLab du projet.

3. DÃ©cider du mode de dÃ©ploiement :
   
   - DÃ©ploiement direct depuis GitLab CI via SSH vers EC2
   
   - Ou dÃ©ploiement via un runner installÃ© sur EC2 (encore plus simple)

RÃ©sultat attendu :

- Le dÃ©pÃ´t contient tout, et le Registry est prÃªt Ã  recevoir des images.

---

## 2) Standardiser les images Docker

1. DÃ©finir la convention de nom dâ€™image :
   
   - Image backend = registry GitLab du projet + nom backend

2. DÃ©finir la stratÃ©gie de tags :
   
   - Tag immuable = hash du commit
   
   - Tag de confort = latest (optionnel)

RÃ©sultat attendu :

- Chaque pipeline produit une image traÃ§able.

---

## 3) Adapter les manifests pour consommer lâ€™image GitLab

1. Le Deployment backend doit pointer vers lâ€™image du Registry GitLab.

2. Le tag doit Ãªtre pilotÃ© par le pipeline :
   
   - Soit via remplacement de valeur au moment du dÃ©ploiement
   
   - Soit via un fichier de valeurs ou overlay (Kustomize/Helm)

RÃ©sultat attendu :

- Le mÃªme manifest peut Ãªtre dÃ©ployÃ© avec des versions diffÃ©rentes sans modification manuelle.

---

## 4) PrÃ©parer lâ€™accÃ¨s Kubernetes depuis EC2

Tu as une EC2 dÃ©jÃ  configurÃ©e : il faut clarifier 2 points cÃ´tÃ© EC2.

1. OÃ¹ tourne Kubernetes :
   
   - Minikube sur EC2
   
   - Ou cluster externe accessible depuis EC2

2. OÃ¹ se trouve la configuration kubeconfig :
   
   - Fichier local sur EC2
   
   - Ou contenu injectÃ© via variable CI

RÃ©sultat attendu :

- Depuis EC2, kubectl fonctionne et pointe vers le bon cluster.

---

## 5) Organiser les scripts sh pour usage pipeline

Objectif : les scripts sh doivent pouvoir Ãªtre appelÃ©s en pipeline, sans interaction.

1. Chaque script doit accepter des entrÃ©es via variables dâ€™environnement :
   
   - Namespace
   
   - Nom dâ€™image backend
   
   - Tag dâ€™image backend
   
   - Mode minikube ou cluster standard

2. Chaque script doit produire des sorties lisibles :
   
   - Afficher les ressources crÃ©Ã©es
   
   - Afficher les tests exÃ©cutÃ©s
   
   - Afficher les erreurs clairement

RÃ©sultat attendu :

- Les scripts sont utilisables en mode non interactif dans GitLab CI.

---

## 6) Concevoir le pipeline GitLab CI

Pipeline recommandÃ© en 4 stages.

### Stage A â€“ Validation

1. VÃ©rifier la structure du dÃ©pÃ´t.

2. VÃ©rifier la qualitÃ© :
   
   - lint yaml (manifests)
   
   - lint shell (scripts)
   
   - vÃ©rification basique Python (optionnel)

RÃ©sultat attendu :

- Le pipeline Ã©choue tÃ´t si un fichier est cassÃ©.

---

### Stage B â€“ Build

1. Construire lâ€™image backend.

2. Taguer lâ€™image avec :
   
   - tag commit
   
   - tag latest (optionnel)

RÃ©sultat attendu :

- Une image prÃªte Ã  Ãªtre push.

---

### Stage C â€“ Push Registry GitLab

1. Authentifier Docker sur le Registry GitLab.

2. Pousser les tags.

RÃ©sultat attendu :

- Lâ€™image est disponible dans GitLab Container Registry.

---

### Stage D â€“ Deploy sur EC2

Deux options propres.

Option 1 : GitLab CI se connecte en SSH sur EC2

1. Ouvrir une session SSH non interactive.

2. Sur EC2 :
   
   - rÃ©cupÃ©rer le projet (clone ou pull)
   
   - exÃ©cuter le script de dÃ©ploiement
   
   - appliquer les manifests
   
   - lancer les tests

Option 2 : Runner GitLab installÃ© sur EC2

1. Le job tourne directement sur EC2.

2. Pas besoin de SSH.

3. Le job exÃ©cute scripts et kubectl localement.

RÃ©sultat attendu :

- Le dÃ©ploiement est automatique, et les tests confirment le fil rouge.
