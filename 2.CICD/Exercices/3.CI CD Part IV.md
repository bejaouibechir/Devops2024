### Exercice 21 : **Orchestration des pipelines avec des pipelines monorepo**
Crée un pipeline pour un projet **monorepo** qui ne déclenche que les pipelines correspondant aux sous-projets modifiés dans un commit (par exemple, deux services distincts).

#### Solution :
```yaml
stages:
  - analyze
  - build

analyze_changes:
  script:
    - |
      if git diff --name-only HEAD~1 | grep '^service1/'; then
        echo "service1 modifié"
        touch service1_trigger
      fi
      if git diff --name-only HEAD~1 | grep '^service2/'; then
        echo "service2 modifié"
        touch service2_trigger
      fi
  artifacts:
    paths:
      - service1_trigger
      - service2_trigger

build_service1:
  stage: build
  script:
    - echo "Construction du service 1"
  rules:
    - exists:
        - service1_trigger

build_service2:
  stage: build
  script:
    - echo "Construction du service 2"
  rules:
    - exists:
        - service2_trigger
```
- **Explication** : Ce pipeline analyse les fichiers modifiés dans le commit pour décider si le service 1 ou le service 2 doit être construit. Le fichier trigger est utilisé pour conditionner l’exécution des jobs `build_service1` et `build_service2`.

---

### Exercice 22 : **Gestion des dépendances inter-jobs avec `needs`**
Crée un pipeline où certains jobs dépendent des artefacts générés par d'autres jobs dans le même stage.

#### Solution :
```yaml
stages:
  - build
  - test

build_job1:
  stage: build
  script:
    - echo "Job 1" > output1.txt
  artifacts:
    paths:
      - output1.txt

build_job2:
  stage: build
  script:
    - echo "Job 2" > output2.txt
  artifacts:
    paths:
      - output2.txt

test_job:
  stage: test
  needs:
    - job: build_job1
    - job: build_job2
  script:
    - cat output1.txt
    - cat output2.txt
```
- **Explication** : Le job `test_job` dépend des jobs `build_job1` et `build_job2` et utilise leurs artefacts pour fonctionner correctement. L'option `needs` garantit que ces jobs soient exécutés avant.

---

### Exercice 23 : **Utilisation avancée des environnements avec des révisions de déploiement**
Crée un pipeline où chaque déploiement est associé à une **révision** pour traquer les versions déployées sur plusieurs environnements.

#### Solution :
```yaml
stages:
  - deploy

deploy_staging:
  stage: deploy
  script:
    - echo "Déploiement sur staging"
  environment:
    name: staging
    on_stop: stop_staging

deploy_production:
  stage: deploy
  script:
    - echo "Déploiement sur production"
  environment:
    name: production
    on_stop: stop_production

stop_staging:
  script:
    - echo "Arrêt de l'environnement staging"
  environment:
    name: staging
    action: stop

stop_production:
  script:
    - echo "Arrêt de l'environnement production"
  environment:
    name: production
    action: stop
```
- **Explication** : Le pipeline déploie sur des environnements distincts (staging et production) avec des jobs spécifiques pour les arrêter en cas de besoin, grâce à l'option `on_stop`.

---

### Exercice 24 : **Exécution conditionnelle avec plusieurs conditions combinées**
Crée un pipeline où un job s'exécute uniquement si certaines conditions multiples sont remplies (par exemple, branche, tag, et présence d'une variable).

#### Solution :
```yaml
conditional_job:
  script:
    - echo "Job exécuté si toutes les conditions sont réunies"
  rules:
    - if: '$CI_COMMIT_REF_NAME == "main" && $CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+$/ && $MY_VAR == "enabled"'
```
- **Explication** : Le job s'exécute uniquement si la branche est `main`, si le commit est tagué avec un schéma de version (`vX.X.X`), et si la variable `MY_VAR` est définie sur `enabled`.

---

### Exercice 25 : **Personnalisation des runners avec des images Docker spécifiques**
Crée un pipeline où les jobs utilisent des **images Docker personnalisées** pour des environnements spécifiques.

#### Solution :
```yaml
build_with_node:
  image: node:14-alpine
  script:
    - echo "Construction avec Node.js"

build_with_python:
  image: python:3.8-alpine
  script:
    - echo "Construction avec Python"
```
- **Explication** : Chaque job utilise une image Docker différente pour configurer l'environnement en fonction des besoins (ici, Node.js et Python).

---

### Exercice 26 : **Création et utilisation de templates de pipelines**
Crée un **template** de pipeline qui peut être réutilisé dans d'autres projets GitLab CI pour partager des logiques communes.

#### Solution :
Dans le projet template :
```yaml
# pipeline_template.yml
build_template:
  script:
    - echo "Job de compilation depuis le template"
```

Dans un autre projet :
```yaml
include:
  - project: 'group/project-template'
    file: '/pipeline_template.yml'

build_job:
  extends: build_template
```
- **Explication** : Le pipeline `build_job` dans un projet externe réutilise le `build_template` défini dans un autre projet GitLab.

---

### Exercice 27 : **Orchestration de pipelines complexes avec `dag`**
Crée un pipeline orchestré par un **DAG (Directed Acyclic Graph)** où les jobs sont exécutés en parallèle selon leurs dépendances plutôt que par stage séquentiel.

#### Solution :
```yaml
stages:
  - prepare
  - build
  - test

prepare:
  script:
    - echo "Préparation"
  stage: prepare

build_job:
  script:
    - echo "Compilation"
  stage: build
  needs:
    - prepare

test_job:
  script:
    - echo "Test"
  stage: test
  needs:
    - build_job
```
- **Explication** : L'exécution est basée sur les dépendances (`needs`) plutôt que sur les stages séquentiels, permettant des exécutions parallèles et plus rapides.

---

### Exercice 28 : **Exploitation de variables sécurisées avec HashiCorp Vault**
Crée un pipeline qui intègre HashiCorp Vault pour extraire et utiliser des variables secrètes sécurisées.

#### Solution :
```yaml
deploy:
  script:
    - echo "Déploiement avec des secrets"
    - echo "Token d'accès: $VAULT_SECRET_TOKEN"
  secrets:
    VAULT_SECRET_TOKEN:
      vault: path/to/secret/token
```
- **Explication** : Les secrets sont récupérés directement depuis HashiCorp Vault et utilisés dans le pipeline sans être exposés dans les logs.

---

### Exercice 29 : **Utilisation des jobs `parallel` pour des tests sur des configurations multiples**
Crée un pipeline où un job exécute des tests sur plusieurs configurations différentes en parallèle.

#### Solution :
```yaml
test_in_parallel:
  script:
    - echo "Test sur $CONFIG"
  parallel:
    matrix:
      - CONFIG: ["config1", "config2", "config3"]
```
- **Explication** : Le job `test_in_parallel` est exécuté sur trois configurations différentes (`config1`, `config2`, `config3`) en parallèle, ce qui accélère le processus de test.

---

### Exercice 30 : **Pipelines multiniveaux avec utilisation de multiples `trigger`**
Crée un pipeline où chaque niveau de pipeline déclenche le suivant, formant une chaîne de pipelines multiniveaux.

#### Solution :
```yaml
stages:
  - trigger_level_1

trigger_level_1:
  script:
    - echo "Déclenchement du niveau 1"
  trigger:
    project: 'group/level1-pipeline'
    branch: master

trigger_level_2:
  stage: trigger_level_1
  script:
    - echo "Déclenchement du niveau 2"
  trigger:
    project: 'group/level2-pipeline'
    branch: master
```
- **Explication** : Ce pipeline déclenche un premier pipeline dans le projet `level1-pipeline`, qui lui-même déclenche un autre pipeline dans `level2-pipeline`. Cela permet d'orchestrer plusieurs pipelines sur différents projets en chaîne.

